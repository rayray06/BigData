// ============================================================================
//
// Copyright (c) 2006-2015, Talend Inc.
//
// This source code has been automatically generated by_Talend Open Studio for Big Data
// / Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


package bigdata_project.extract_visite_0_1;

import routines.Numeric;
import routines.DataOperation;
import routines.TalendDataGenerator;
import routines.TalendStringUtil;
import routines.TalendString;
import routines.StringHandling;
import routines.Relational;
import routines.TalendDate;
import routines.Mathematical;
import routines.system.*;
import routines.system.api.*;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;
import java.math.BigDecimal;
import java.io.ByteArrayOutputStream;
import java.io.ByteArrayInputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.ObjectOutputStream;
import java.io.ObjectInputStream;
import java.io.IOException;
import java.util.Comparator;
 





@SuppressWarnings("unused")

/**
 * Job: Extract_Visite Purpose: <br>
 * Description:  <br>
 * @author ray-hann06@hotmail.fr
 * @version 7.3.1.20200219_1130
 * @status 
 */
public class Extract_Visite implements TalendJob {

protected static void logIgnoredError(String message, Throwable cause) {
       System.err.println(message);
       if (cause != null) {
               cause.printStackTrace();
       }

}


	public final Object obj = new Object();

	// for transmiting parameters purpose
	private Object valueObject = null;

	public Object getValueObject() {
		return this.valueObject;
	}

	public void setValueObject(Object valueObject) {
		this.valueObject = valueObject;
	}
	
	private final static String defaultCharset = java.nio.charset.Charset.defaultCharset().name();

	
	private final static String utf8Charset = "UTF-8";
	//contains type for every context property
	public class PropertiesWithType extends java.util.Properties {
		private static final long serialVersionUID = 1L;
		private java.util.Map<String,String> propertyTypes = new java.util.HashMap<>();
		
		public PropertiesWithType(java.util.Properties properties){
			super(properties);
		}
		public PropertiesWithType(){
			super();
		}
		
		public void setContextType(String key, String type) {
			propertyTypes.put(key,type);
		}
	
		public String getContextType(String key) {
			return propertyTypes.get(key);
		}
	}
	
	// create and load default properties
	private java.util.Properties defaultProps = new java.util.Properties();
	// create application properties with default
	public class ContextProperties extends PropertiesWithType {

		private static final long serialVersionUID = 1L;

		public ContextProperties(java.util.Properties properties){
			super(properties);
		}
		public ContextProperties(){
			super();
		}

		public void synchronizeContext(){
			
			if(HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable != null){
				
					this.setProperty("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable", HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable.toString());
				
			}
			
			if(HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy != null){
				
					this.setProperty("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy", HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy.toString());
				
			}
			
			if(HadoopHDFS_HdfsFileSeparator != null){
				
					this.setProperty("HadoopHDFS_HdfsFileSeparator", HadoopHDFS_HdfsFileSeparator.toString());
				
			}
			
			if(HadoopHDFS_HdfsRowSeparator != null){
				
					this.setProperty("HadoopHDFS_HdfsRowSeparator", HadoopHDFS_HdfsRowSeparator.toString());
				
			}
			
			if(HadoopHDFS_HdfsUser != null){
				
					this.setProperty("HadoopHDFS_HdfsUser", HadoopHDFS_HdfsUser.toString());
				
			}
			
			if(HadoopHDFS_Hospi != null){
				
					this.setProperty("HadoopHDFS_Hospi", HadoopHDFS_Hospi.toString());
				
			}
			
			if(HadoopHDFS_VisiteFile != null){
				
					this.setProperty("HadoopHDFS_VisiteFile", HadoopHDFS_VisiteFile.toString());
				
			}
			
			if(ProjectHadoopCluster_NameNodeUri != null){
				
					this.setProperty("ProjectHadoopCluster_NameNodeUri", ProjectHadoopCluster_NameNodeUri.toString());
				
			}
			
			if(ProjectHadoopCluster_User != null){
				
					this.setProperty("ProjectHadoopCluster_User", ProjectHadoopCluster_User.toString());
				
			}
			
		}

public String HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable;
public String getHadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable(){
	return this.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable;
}
public String HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy;
public String getHadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy(){
	return this.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy;
}
public String HadoopHDFS_HdfsFileSeparator;
public String getHadoopHDFS_HdfsFileSeparator(){
	return this.HadoopHDFS_HdfsFileSeparator;
}
public String HadoopHDFS_HdfsRowSeparator;
public String getHadoopHDFS_HdfsRowSeparator(){
	return this.HadoopHDFS_HdfsRowSeparator;
}
public String HadoopHDFS_HdfsUser;
public String getHadoopHDFS_HdfsUser(){
	return this.HadoopHDFS_HdfsUser;
}
public String HadoopHDFS_Hospi;
public String getHadoopHDFS_Hospi(){
	return this.HadoopHDFS_Hospi;
}
public String HadoopHDFS_VisiteFile;
public String getHadoopHDFS_VisiteFile(){
	return this.HadoopHDFS_VisiteFile;
}
public String ProjectHadoopCluster_NameNodeUri;
public String getProjectHadoopCluster_NameNodeUri(){
	return this.ProjectHadoopCluster_NameNodeUri;
}
public String ProjectHadoopCluster_User;
public String getProjectHadoopCluster_User(){
	return this.ProjectHadoopCluster_User;
}
	}
	protected ContextProperties context = new ContextProperties(); // will be instanciated by MS.
	public ContextProperties getContext() {
		return this.context;
	}
	private final String jobVersion = "0.1";
	private final String jobName = "Extract_Visite";
	private final String projectName = "BIGDATA_PROJECT";
	public Integer errorCode = null;
	private String currentComponent = "";
	
		private final java.util.Map<String, Object> globalMap = new java.util.HashMap<String, Object>();
        private final static java.util.Map<String, Object> junitGlobalMap = new java.util.HashMap<String, Object>();
	
		private final java.util.Map<String, Long> start_Hash = new java.util.HashMap<String, Long>();
		private final java.util.Map<String, Long> end_Hash = new java.util.HashMap<String, Long>();
		private final java.util.Map<String, Boolean> ok_Hash = new java.util.HashMap<String, Boolean>();
		public  final java.util.List<String[]> globalBuffer = new java.util.ArrayList<String[]>();
	

private RunStat runStat = new RunStat();

	// OSGi DataSource
	private final static String KEY_DB_DATASOURCES = "KEY_DB_DATASOURCES";
	
	private final static String KEY_DB_DATASOURCES_RAW = "KEY_DB_DATASOURCES_RAW";

	public void setDataSources(java.util.Map<String, javax.sql.DataSource> dataSources) {
		java.util.Map<String, routines.system.TalendDataSource> talendDataSources = new java.util.HashMap<String, routines.system.TalendDataSource>();
		for (java.util.Map.Entry<String, javax.sql.DataSource> dataSourceEntry : dataSources.entrySet()) {
			talendDataSources.put(dataSourceEntry.getKey(), new routines.system.TalendDataSource(dataSourceEntry.getValue()));
		}
		globalMap.put(KEY_DB_DATASOURCES, talendDataSources);
		globalMap.put(KEY_DB_DATASOURCES_RAW, new java.util.HashMap<String, javax.sql.DataSource>(dataSources));
	}


private final java.io.ByteArrayOutputStream baos = new java.io.ByteArrayOutputStream();
private final java.io.PrintStream errorMessagePS = new java.io.PrintStream(new java.io.BufferedOutputStream(baos));

public String getExceptionStackTrace() {
	if ("failure".equals(this.getStatus())) {
		errorMessagePS.flush();
		return baos.toString();
	}
	return null;
}

private Exception exception;

public Exception getException() {
	if ("failure".equals(this.getStatus())) {
		return this.exception;
	}
	return null;
}

private class TalendException extends Exception {

	private static final long serialVersionUID = 1L;

	private java.util.Map<String, Object> globalMap = null;
	private Exception e = null;
	private String currentComponent = null;
	private String virtualComponentName = null;
	
	public void setVirtualComponentName (String virtualComponentName){
		this.virtualComponentName = virtualComponentName;
	}

	private TalendException(Exception e, String errorComponent, final java.util.Map<String, Object> globalMap) {
		this.currentComponent= errorComponent;
		this.globalMap = globalMap;
		this.e = e;
	}

	public Exception getException() {
		return this.e;
	}

	public String getCurrentComponent() {
		return this.currentComponent;
	}

	
    public String getExceptionCauseMessage(Exception e){
        Throwable cause = e;
        String message = null;
        int i = 10;
        while (null != cause && 0 < i--) {
            message = cause.getMessage();
            if (null == message) {
                cause = cause.getCause();
            } else {
                break;          
            }
        }
        if (null == message) {
            message = e.getClass().getName();
        }   
        return message;
    }

	@Override
	public void printStackTrace() {
		if (!(e instanceof TalendException || e instanceof TDieException)) {
			if(virtualComponentName!=null && currentComponent.indexOf(virtualComponentName+"_")==0){
				globalMap.put(virtualComponentName+"_ERROR_MESSAGE",getExceptionCauseMessage(e));
			}
			globalMap.put(currentComponent+"_ERROR_MESSAGE",getExceptionCauseMessage(e));
			System.err.println("Exception in component " + currentComponent + " (" + jobName + ")");
		}
		if (!(e instanceof TDieException)) {
			if(e instanceof TalendException){
				e.printStackTrace();
			} else {
				e.printStackTrace();
				e.printStackTrace(errorMessagePS);
				Extract_Visite.this.exception = e;
			}
		}
		if (!(e instanceof TalendException)) {
		try {
			for (java.lang.reflect.Method m : this.getClass().getEnclosingClass().getMethods()) {
				if (m.getName().compareTo(currentComponent + "_error") == 0) {
					m.invoke(Extract_Visite.this, new Object[] { e , currentComponent, globalMap});
					break;
				}
			}

			if(!(e instanceof TDieException)){
			}
		} catch (Exception e) {
			this.e.printStackTrace();
		}
		}
	}
}

			public void tHDFSConnection_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {
				
				end_Hash.put(errorComponent, System.currentTimeMillis());
				
				status = "failure";
				
					tHDFSConnection_1_onSubJobError(exception, errorComponent, globalMap);
			}
			
			public void tFileInputDelimited_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {
				
				end_Hash.put(errorComponent, System.currentTimeMillis());
				
				status = "failure";
				
					tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
			}
			
			public void tMap_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {
				
				end_Hash.put(errorComponent, System.currentTimeMillis());
				
				status = "failure";
				
					tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
			}
			
			public void tHDFSOutput_1_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {
				
				end_Hash.put(errorComponent, System.currentTimeMillis());
				
				status = "failure";
				
					tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
			}
			
			public void tHDFSOutput_2_error(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {
				
				end_Hash.put(errorComponent, System.currentTimeMillis());
				
				status = "failure";
				
					tFileInputDelimited_1_onSubJobError(exception, errorComponent, globalMap);
			}
			
			public void tHDFSConnection_1_onSubJobError(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {

resumeUtil.addLog("SYSTEM_LOG", "NODE:"+ errorComponent, "", Thread.currentThread().getId()+ "", "FATAL", "", exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception),"");

			}
			public void tFileInputDelimited_1_onSubJobError(Exception exception, String errorComponent, final java.util.Map<String, Object> globalMap) throws TalendException {

resumeUtil.addLog("SYSTEM_LOG", "NODE:"+ errorComponent, "", Thread.currentThread().getId()+ "", "FATAL", "", exception.getMessage(), ResumeUtil.getExceptionStackTrace(exception),"");

			}
	





public void tHDFSConnection_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
	globalMap.put("tHDFSConnection_1_SUBPROCESS_STATE", 0);

 final boolean execStat = this.execStat;
	
		String iterateId = "";
	
	
	String currentComponent = "";
	java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

	try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { //start the resume
				globalResumeTicket = true;



		


	
	/**
	 * [tHDFSConnection_1 begin ] start
	 */

	

	
		
		ok_Hash.put("tHDFSConnection_1", false);
		start_Hash.put("tHDFSConnection_1", System.currentTimeMillis());
		
	
	currentComponent="tHDFSConnection_1";

	
		int tos_count_tHDFSConnection_1 = 0;
		

	
	
	
		org.apache.hadoop.conf.Configuration conf_tHDFSConnection_1 = new org.apache.hadoop.conf.Configuration();
		conf_tHDFSConnection_1.set("fs.default.name", context.ProjectHadoopCluster_NameNodeUri);
			conf_tHDFSConnection_1.set("fs.default.name", context.ProjectHadoopCluster_NameNodeUri);
		
				conf_tHDFSConnection_1.set("dfs.client.use.datanode.hostname", "true");
	
			conf_tHDFSConnection_1.set("dfs.client.block.write.replace-datanode-on-failure.enable" ,"false");
			conf_tHDFSConnection_1.set("dfs.client.block.write.replace-datanode-on-failure.policy" ,"NEVER");
	org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSConnection_1);
	globalMap.put("conn_tHDFSConnection_1",conf_tHDFSConnection_1);

 



/**
 * [tHDFSConnection_1 begin ] stop
 */
	
	/**
	 * [tHDFSConnection_1 main ] start
	 */

	

	
	
	currentComponent="tHDFSConnection_1";

	

 


	tos_count_tHDFSConnection_1++;

/**
 * [tHDFSConnection_1 main ] stop
 */
	
	/**
	 * [tHDFSConnection_1 process_data_begin ] start
	 */

	

	
	
	currentComponent="tHDFSConnection_1";

	

 



/**
 * [tHDFSConnection_1 process_data_begin ] stop
 */
	
	/**
	 * [tHDFSConnection_1 process_data_end ] start
	 */

	

	
	
	currentComponent="tHDFSConnection_1";

	

 



/**
 * [tHDFSConnection_1 process_data_end ] stop
 */
	
	/**
	 * [tHDFSConnection_1 end ] start
	 */

	

	
	
	currentComponent="tHDFSConnection_1";

	

 

ok_Hash.put("tHDFSConnection_1", true);
end_Hash.put("tHDFSConnection_1", System.currentTimeMillis());




/**
 * [tHDFSConnection_1 end ] stop
 */
				}//end the resume

				
				    			if(resumeEntryMethodName == null || globalResumeTicket){
				    				resumeUtil.addLog("CHECKPOINT", "CONNECTION:SUBJOB_OK:tHDFSConnection_1:OnSubjobOk", "", Thread.currentThread().getId() + "", "", "", "", "", "");
								}	    				    			
					    	
								if(execStat){    	
									runStat.updateStatOnConnection("OnSubjobOk1", 0, "ok");
								} 
							
							tFileInputDelimited_1Process(globalMap); 
						



	
			}catch(java.lang.Exception e){	
				
				TalendException te = new TalendException(e, currentComponent, globalMap);
				
				throw te;
			}catch(java.lang.Error error){	
				
					runStat.stopThreadStat();
				
				throw error;
			}finally{
				
				try{
					
	
	/**
	 * [tHDFSConnection_1 finally ] start
	 */

	

	
	
	currentComponent="tHDFSConnection_1";

	

 



/**
 * [tHDFSConnection_1 finally ] stop
 */
				}catch(java.lang.Exception e){	
					//ignore
				}catch(java.lang.Error error){
					//ignore
				}
				resourceMap = null;
			}
		

		globalMap.put("tHDFSConnection_1_SUBPROCESS_STATE", 1);
	}
	


public static class OutStruct implements routines.system.IPersistableRow<OutStruct> {
    final static byte[] commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite = new byte[0];
    static byte[] commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[0];
	protected static final int DEFAULT_HASHCODE = 1;
    protected static final int PRIME = 31;
    protected int hashCode = DEFAULT_HASHCODE;
    public boolean hashCodeDirty = true;

    public String loopKey;



	
			    public String Num_Hospitalisation;

				public String getNum_Hospitalisation () {
					return this.Num_Hospitalisation;
				}
				
			    public java.util.Date Date_Entree;

				public java.util.Date getDate_Entree () {
					return this.Date_Entree;
				}
				
			    public Integer Jour_Hospitalisation;

				public Integer getJour_Hospitalisation () {
					return this.Jour_Hospitalisation;
				}
				


	@Override
	public int hashCode() {
		if (this.hashCodeDirty) {
			final int prime = PRIME;
			int result = DEFAULT_HASHCODE;
	
						result = prime * result + ((this.Num_Hospitalisation == null) ? 0 : this.Num_Hospitalisation.hashCode());
					
    		this.hashCode = result;
    		this.hashCodeDirty = false;
		}
		return this.hashCode;
	}

	@Override
	public boolean equals(Object obj) {
		if (this == obj) return true;
		if (obj == null) return false;
		if (getClass() != obj.getClass()) return false;
		final OutStruct other = (OutStruct) obj;
		
						if (this.Num_Hospitalisation == null) {
							if (other.Num_Hospitalisation != null)
								return false;
						
						} else if (!this.Num_Hospitalisation.equals(other.Num_Hospitalisation))
						
							return false;
					

		return true;
    }

	public void copyDataTo(OutStruct other) {

		other.Num_Hospitalisation = this.Num_Hospitalisation;
	            other.Date_Entree = this.Date_Entree;
	            other.Jour_Hospitalisation = this.Jour_Hospitalisation;
	            
	}

	public void copyKeysDataTo(OutStruct other) {

		other.Num_Hospitalisation = this.Num_Hospitalisation;
	            	
	}




	private String readString(ObjectInputStream dis) throws IOException{
		String strReturn = null;
		int length = 0;
        length = dis.readInt();
		if (length == -1) {
			strReturn = null;
		} else {
			if(length > commonByteArray_BIGDATA_PROJECT_Extract_Visite.length) {
				if(length < 1024 && commonByteArray_BIGDATA_PROJECT_Extract_Visite.length == 0) {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[1024];
				} else {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[2 * length];
   				}
			}
			dis.readFully(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length);
			strReturn = new String(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length, utf8Charset);
		}
		return strReturn;
	}

    private void writeString(String str, ObjectOutputStream dos) throws IOException{
		if(str == null) {
            dos.writeInt(-1);
		} else {
            byte[] byteArray = str.getBytes(utf8Charset);
	    	dos.writeInt(byteArray.length);
			dos.write(byteArray);
    	}
    }

	private java.util.Date readDate(ObjectInputStream dis) throws IOException{
		java.util.Date dateReturn = null;
        int length = 0;
        length = dis.readByte();
		if (length == -1) {
			dateReturn = null;
		} else {
	    	dateReturn = new Date(dis.readLong());
		}
		return dateReturn;
	}

    private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException{
		if(date1 == null) {
            dos.writeByte(-1);
		} else {
			dos.writeByte(0);
	    	dos.writeLong(date1.getTime());
    	}
    }
	private Integer readInteger(ObjectInputStream dis) throws IOException{
		Integer intReturn;
        int length = 0;
        length = dis.readByte();
		if (length == -1) {
			intReturn = null;
		} else {
	    	intReturn = dis.readInt();
		}
		return intReturn;
	}

	private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException{
		if(intNum == null) {
            dos.writeByte(-1);
		} else {
			dos.writeByte(0);
	    	dos.writeInt(intNum);
    	}
	}

    public void readData(ObjectInputStream dis) {

		synchronized(commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite) {

        	try {

        		int length = 0;
		
					this.Num_Hospitalisation = readString(dis);
					
					this.Date_Entree = readDate(dis);
					
						this.Jour_Hospitalisation = readInteger(dis);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);

		

        }

		

      }


    }

    public void writeData(ObjectOutputStream dos) {
        try {

		
					// String
				
						writeString(this.Num_Hospitalisation,dos);
					
					// java.util.Date
				
						writeDate(this.Date_Entree,dos);
					
					// Integer
				
						writeInteger(this.Jour_Hospitalisation,dos);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);
        }


    }


    public String toString() {

		StringBuilder sb = new StringBuilder();
		sb.append(super.toString());
		sb.append("[");
		sb.append("Num_Hospitalisation="+Num_Hospitalisation);
		sb.append(",Date_Entree="+String.valueOf(Date_Entree));
		sb.append(",Jour_Hospitalisation="+String.valueOf(Jour_Hospitalisation));
	    sb.append("]");

	    return sb.toString();
    }

    /**
     * Compare keys
     */
    public int compareTo(OutStruct other) {

		int returnValue = -1;
		
						returnValue = checkNullsAndCompare(this.Num_Hospitalisation, other.Num_Hospitalisation);
						if(returnValue != 0) {
							return returnValue;
						}

					
	    return returnValue;
    }


    private int checkNullsAndCompare(Object object1, Object object2) {
        int returnValue = 0;
		if (object1 instanceof Comparable && object2 instanceof Comparable) {
            returnValue = ((Comparable) object1).compareTo(object2);
        } else if (object1 != null && object2 != null) {
            returnValue = compareStrings(object1.toString(), object2.toString());
        } else if (object1 == null && object2 != null) {
            returnValue = 1;
        } else if (object1 != null && object2 == null) {
            returnValue = -1;
        } else {
            returnValue = 0;
        }

        return returnValue;
    }

    private int compareStrings(String string1, String string2) {
        return string1.compareTo(string2);
    }


}

public static class FaitStruct implements routines.system.IPersistableRow<FaitStruct> {
    final static byte[] commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite = new byte[0];
    static byte[] commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[0];
	protected static final int DEFAULT_HASHCODE = 1;
    protected static final int PRIME = 31;
    protected int hashCode = DEFAULT_HASHCODE;
    public boolean hashCodeDirty = true;

    public String loopKey;



	
			    public String Num_Hospitalisation;

				public String getNum_Hospitalisation () {
					return this.Num_Hospitalisation;
				}
				
			    public Integer Id_patient;

				public Integer getId_patient () {
					return this.Id_patient;
				}
				
			    public String Code_diagnostic;

				public String getCode_diagnostic () {
					return this.Code_diagnostic;
				}
				


	@Override
	public int hashCode() {
		if (this.hashCodeDirty) {
			final int prime = PRIME;
			int result = DEFAULT_HASHCODE;
	
						result = prime * result + ((this.Num_Hospitalisation == null) ? 0 : this.Num_Hospitalisation.hashCode());
					
    		this.hashCode = result;
    		this.hashCodeDirty = false;
		}
		return this.hashCode;
	}

	@Override
	public boolean equals(Object obj) {
		if (this == obj) return true;
		if (obj == null) return false;
		if (getClass() != obj.getClass()) return false;
		final FaitStruct other = (FaitStruct) obj;
		
						if (this.Num_Hospitalisation == null) {
							if (other.Num_Hospitalisation != null)
								return false;
						
						} else if (!this.Num_Hospitalisation.equals(other.Num_Hospitalisation))
						
							return false;
					

		return true;
    }

	public void copyDataTo(FaitStruct other) {

		other.Num_Hospitalisation = this.Num_Hospitalisation;
	            other.Id_patient = this.Id_patient;
	            other.Code_diagnostic = this.Code_diagnostic;
	            
	}

	public void copyKeysDataTo(FaitStruct other) {

		other.Num_Hospitalisation = this.Num_Hospitalisation;
	            	
	}




	private String readString(ObjectInputStream dis) throws IOException{
		String strReturn = null;
		int length = 0;
        length = dis.readInt();
		if (length == -1) {
			strReturn = null;
		} else {
			if(length > commonByteArray_BIGDATA_PROJECT_Extract_Visite.length) {
				if(length < 1024 && commonByteArray_BIGDATA_PROJECT_Extract_Visite.length == 0) {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[1024];
				} else {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[2 * length];
   				}
			}
			dis.readFully(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length);
			strReturn = new String(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length, utf8Charset);
		}
		return strReturn;
	}

    private void writeString(String str, ObjectOutputStream dos) throws IOException{
		if(str == null) {
            dos.writeInt(-1);
		} else {
            byte[] byteArray = str.getBytes(utf8Charset);
	    	dos.writeInt(byteArray.length);
			dos.write(byteArray);
    	}
    }
	private Integer readInteger(ObjectInputStream dis) throws IOException{
		Integer intReturn;
        int length = 0;
        length = dis.readByte();
		if (length == -1) {
			intReturn = null;
		} else {
	    	intReturn = dis.readInt();
		}
		return intReturn;
	}

	private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException{
		if(intNum == null) {
            dos.writeByte(-1);
		} else {
			dos.writeByte(0);
	    	dos.writeInt(intNum);
    	}
	}

    public void readData(ObjectInputStream dis) {

		synchronized(commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite) {

        	try {

        		int length = 0;
		
					this.Num_Hospitalisation = readString(dis);
					
						this.Id_patient = readInteger(dis);
					
					this.Code_diagnostic = readString(dis);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);

		

        }

		

      }


    }

    public void writeData(ObjectOutputStream dos) {
        try {

		
					// String
				
						writeString(this.Num_Hospitalisation,dos);
					
					// Integer
				
						writeInteger(this.Id_patient,dos);
					
					// String
				
						writeString(this.Code_diagnostic,dos);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);
        }


    }


    public String toString() {

		StringBuilder sb = new StringBuilder();
		sb.append(super.toString());
		sb.append("[");
		sb.append("Num_Hospitalisation="+Num_Hospitalisation);
		sb.append(",Id_patient="+String.valueOf(Id_patient));
		sb.append(",Code_diagnostic="+Code_diagnostic);
	    sb.append("]");

	    return sb.toString();
    }

    /**
     * Compare keys
     */
    public int compareTo(FaitStruct other) {

		int returnValue = -1;
		
						returnValue = checkNullsAndCompare(this.Num_Hospitalisation, other.Num_Hospitalisation);
						if(returnValue != 0) {
							return returnValue;
						}

					
	    return returnValue;
    }


    private int checkNullsAndCompare(Object object1, Object object2) {
        int returnValue = 0;
		if (object1 instanceof Comparable && object2 instanceof Comparable) {
            returnValue = ((Comparable) object1).compareTo(object2);
        } else if (object1 != null && object2 != null) {
            returnValue = compareStrings(object1.toString(), object2.toString());
        } else if (object1 == null && object2 != null) {
            returnValue = 1;
        } else if (object1 != null && object2 == null) {
            returnValue = -1;
        } else {
            returnValue = 0;
        }

        return returnValue;
    }

    private int compareStrings(String string1, String string2) {
        return string1.compareTo(string2);
    }


}

public static class row1Struct implements routines.system.IPersistableRow<row1Struct> {
    final static byte[] commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite = new byte[0];
    static byte[] commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[0];

	
			    public String Num_Hospitalisation;

				public String getNum_Hospitalisation () {
					return this.Num_Hospitalisation;
				}
				
			    public Integer Id_patient;

				public Integer getId_patient () {
					return this.Id_patient;
				}
				
			    public String identifiant_organisation;

				public String getIdentifiant_organisation () {
					return this.identifiant_organisation;
				}
				
			    public String Code_diagnostic;

				public String getCode_diagnostic () {
					return this.Code_diagnostic;
				}
				
			    public String Suite_diagnostic_consultation;

				public String getSuite_diagnostic_consultation () {
					return this.Suite_diagnostic_consultation;
				}
				
			    public java.util.Date Date_Entree;

				public java.util.Date getDate_Entree () {
					return this.Date_Entree;
				}
				
			    public Integer Jour_Hospitalisation;

				public Integer getJour_Hospitalisation () {
					return this.Jour_Hospitalisation;
				}
				



	private String readString(ObjectInputStream dis) throws IOException{
		String strReturn = null;
		int length = 0;
        length = dis.readInt();
		if (length == -1) {
			strReturn = null;
		} else {
			if(length > commonByteArray_BIGDATA_PROJECT_Extract_Visite.length) {
				if(length < 1024 && commonByteArray_BIGDATA_PROJECT_Extract_Visite.length == 0) {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[1024];
				} else {
   					commonByteArray_BIGDATA_PROJECT_Extract_Visite = new byte[2 * length];
   				}
			}
			dis.readFully(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length);
			strReturn = new String(commonByteArray_BIGDATA_PROJECT_Extract_Visite, 0, length, utf8Charset);
		}
		return strReturn;
	}

    private void writeString(String str, ObjectOutputStream dos) throws IOException{
		if(str == null) {
            dos.writeInt(-1);
		} else {
            byte[] byteArray = str.getBytes(utf8Charset);
	    	dos.writeInt(byteArray.length);
			dos.write(byteArray);
    	}
    }
	private Integer readInteger(ObjectInputStream dis) throws IOException{
		Integer intReturn;
        int length = 0;
        length = dis.readByte();
		if (length == -1) {
			intReturn = null;
		} else {
	    	intReturn = dis.readInt();
		}
		return intReturn;
	}

	private void writeInteger(Integer intNum, ObjectOutputStream dos) throws IOException{
		if(intNum == null) {
            dos.writeByte(-1);
		} else {
			dos.writeByte(0);
	    	dos.writeInt(intNum);
    	}
	}

	private java.util.Date readDate(ObjectInputStream dis) throws IOException{
		java.util.Date dateReturn = null;
        int length = 0;
        length = dis.readByte();
		if (length == -1) {
			dateReturn = null;
		} else {
	    	dateReturn = new Date(dis.readLong());
		}
		return dateReturn;
	}

    private void writeDate(java.util.Date date1, ObjectOutputStream dos) throws IOException{
		if(date1 == null) {
            dos.writeByte(-1);
		} else {
			dos.writeByte(0);
	    	dos.writeLong(date1.getTime());
    	}
    }

    public void readData(ObjectInputStream dis) {

		synchronized(commonByteArrayLock_BIGDATA_PROJECT_Extract_Visite) {

        	try {

        		int length = 0;
		
					this.Num_Hospitalisation = readString(dis);
					
						this.Id_patient = readInteger(dis);
					
					this.identifiant_organisation = readString(dis);
					
					this.Code_diagnostic = readString(dis);
					
					this.Suite_diagnostic_consultation = readString(dis);
					
					this.Date_Entree = readDate(dis);
					
						this.Jour_Hospitalisation = readInteger(dis);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);

		

        }

		

      }


    }

    public void writeData(ObjectOutputStream dos) {
        try {

		
					// String
				
						writeString(this.Num_Hospitalisation,dos);
					
					// Integer
				
						writeInteger(this.Id_patient,dos);
					
					// String
				
						writeString(this.identifiant_organisation,dos);
					
					// String
				
						writeString(this.Code_diagnostic,dos);
					
					// String
				
						writeString(this.Suite_diagnostic_consultation,dos);
					
					// java.util.Date
				
						writeDate(this.Date_Entree,dos);
					
					// Integer
				
						writeInteger(this.Jour_Hospitalisation,dos);
					
        	} catch (IOException e) {
	            throw new RuntimeException(e);
        }


    }


    public String toString() {

		StringBuilder sb = new StringBuilder();
		sb.append(super.toString());
		sb.append("[");
		sb.append("Num_Hospitalisation="+Num_Hospitalisation);
		sb.append(",Id_patient="+String.valueOf(Id_patient));
		sb.append(",identifiant_organisation="+identifiant_organisation);
		sb.append(",Code_diagnostic="+Code_diagnostic);
		sb.append(",Suite_diagnostic_consultation="+Suite_diagnostic_consultation);
		sb.append(",Date_Entree="+String.valueOf(Date_Entree));
		sb.append(",Jour_Hospitalisation="+String.valueOf(Jour_Hospitalisation));
	    sb.append("]");

	    return sb.toString();
    }

    /**
     * Compare keys
     */
    public int compareTo(row1Struct other) {

		int returnValue = -1;
		
	    return returnValue;
    }


    private int checkNullsAndCompare(Object object1, Object object2) {
        int returnValue = 0;
		if (object1 instanceof Comparable && object2 instanceof Comparable) {
            returnValue = ((Comparable) object1).compareTo(object2);
        } else if (object1 != null && object2 != null) {
            returnValue = compareStrings(object1.toString(), object2.toString());
        } else if (object1 == null && object2 != null) {
            returnValue = 1;
        } else if (object1 != null && object2 == null) {
            returnValue = -1;
        } else {
            returnValue = 0;
        }

        return returnValue;
    }

    private int compareStrings(String string1, String string2) {
        return string1.compareTo(string2);
    }


}
public void tFileInputDelimited_1Process(final java.util.Map<String, Object> globalMap) throws TalendException {
	globalMap.put("tFileInputDelimited_1_SUBPROCESS_STATE", 0);

 final boolean execStat = this.execStat;
	
		String iterateId = "";
	
	
	String currentComponent = "";
	java.util.Map<String, Object> resourceMap = new java.util.HashMap<String, Object>();

	try {
			// TDI-39566 avoid throwing an useless Exception
			boolean resumeIt = true;
			if (globalResumeTicket == false && resumeEntryMethodName != null) {
				String currentMethodName = new java.lang.Exception().getStackTrace()[0].getMethodName();
				resumeIt = resumeEntryMethodName.equals(currentMethodName);
			}
			if (resumeIt || globalResumeTicket) { //start the resume
				globalResumeTicket = true;



		row1Struct row1 = new row1Struct();
OutStruct Out = new OutStruct();
FaitStruct Fait = new FaitStruct();





	
	/**
	 * [tHDFSOutput_1 begin ] start
	 */

	

	
		
		ok_Hash.put("tHDFSOutput_1", false);
		start_Hash.put("tHDFSOutput_1", System.currentTimeMillis());
		
	
	currentComponent="tHDFSOutput_1";

	
					if(execStat) {
						runStat.updateStatOnConnection(resourceMap,iterateId,0,0,"Out");
					}
				
		int tos_count_tHDFSOutput_1 = 0;
		

	


String username_tHDFSOutput_1 = "";
org.apache.hadoop.fs.FileSystem fs_tHDFSOutput_1 = null;
	org.apache.hadoop.conf.Configuration conf_tHDFSOutput_1 = new org.apache.hadoop.conf.Configuration();
	
	
		conf_tHDFSOutput_1.set("fs.default.name", context.ProjectHadoopCluster_NameNodeUri);
	
	        conf_tHDFSOutput_1.set("dfs.client.use.datanode.hostname", "true");
	        
				conf_tHDFSOutput_1.set("dfs.client.block.write.replace-datanode-on-failure.enable" ,"false");
			
				conf_tHDFSOutput_1.set("dfs.client.block.write.replace-datanode-on-failure.policy" ,"NEVER");
			
       org.apache.hadoop.security.UserGroupInformation.setConfiguration(conf_tHDFSOutput_1);
		username_tHDFSOutput_1 = "cloudera";
		if(username_tHDFSOutput_1 == null || "".equals(username_tHDFSOutput_1)){
			fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(conf_tHDFSOutput_1);
		}else{
			System.setProperty("HADOOP_USER_NAME", username_tHDFSOutput_1);
			fs_tHDFSOutput_1 = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_tHDFSOutput_1.get("fs.default.name")),conf_tHDFSOutput_1,username_tHDFSOutput_1);
		}	
	

	
	org.apache.hadoop.fs.Path path_tHDFSOutput_1 = new org.apache.hadoop.fs.Path(context.HadoopHDFS_VisiteFile);
	int nb_line_tHDFSOutput_1 = 0;
				
		org.apache.hadoop.fs.FSDataOutputStream fsDataOutputStream_tHDFSOutput_1 = null;
		
			fsDataOutputStream_tHDFSOutput_1 = fs_tHDFSOutput_1.create(path_tHDFSOutput_1, true);
		
		
			java.io.Writer outtHDFSOutput_1 = null;
			outtHDFSOutput_1=new java.io.BufferedWriter(new java.io.OutputStreamWriter(fsDataOutputStream_tHDFSOutput_1));
		

 



/**
 * [tHDFSOutput_1 begin ] stop
 */




	
	/**
	 * [tHDFSOutput_2 begin ] start
	 */

	

	
		
		ok_Hash.put("tHDFSOutput_2", false);
		start_Hash.put("tHDFSOutput_2", System.currentTimeMillis());
		
	
	currentComponent="tHDFSOutput_2";

	
					if(execStat) {
						runStat.updateStatOnConnection(resourceMap,iterateId,0,0,"Fait");
					}
				
		int tos_count_tHDFSOutput_2 = 0;
		

	


String username_tHDFSOutput_2 = "";
org.apache.hadoop.fs.FileSystem fs_tHDFSOutput_2 = null;
	org.apache.hadoop.conf.Configuration conf_tHDFSOutput_2 = (org.apache.hadoop.conf.Configuration)globalMap.get("conn_tHDFSConnection_1");
						
					username_tHDFSOutput_2 = "cloudera";
				if(username_tHDFSOutput_2 == null || "".equals(username_tHDFSOutput_2)){
					fs_tHDFSOutput_2 = org.apache.hadoop.fs.FileSystem.get(conf_tHDFSOutput_2);
				}else{
					System.setProperty("HADOOP_USER_NAME", username_tHDFSOutput_2);
					fs_tHDFSOutput_2 = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(conf_tHDFSOutput_2.get("fs.default.name")),conf_tHDFSOutput_2,username_tHDFSOutput_2);
				}			  		
		  	

	
	org.apache.hadoop.fs.Path path_tHDFSOutput_2 = new org.apache.hadoop.fs.Path(context.HadoopHDFS_Hospi);
	int nb_line_tHDFSOutput_2 = 0;
				
		org.apache.hadoop.fs.FSDataOutputStream fsDataOutputStream_tHDFSOutput_2 = null;
		
			fsDataOutputStream_tHDFSOutput_2 = fs_tHDFSOutput_2.create(path_tHDFSOutput_2, true);
		
		
			java.io.Writer outtHDFSOutput_2 = null;
			outtHDFSOutput_2=new java.io.BufferedWriter(new java.io.OutputStreamWriter(fsDataOutputStream_tHDFSOutput_2));
		

 



/**
 * [tHDFSOutput_2 begin ] stop
 */



	
	/**
	 * [tMap_1 begin ] start
	 */

	

	
		
		ok_Hash.put("tMap_1", false);
		start_Hash.put("tMap_1", System.currentTimeMillis());
		
	
	currentComponent="tMap_1";

	
					if(execStat) {
						runStat.updateStatOnConnection(resourceMap,iterateId,0,0,"row1");
					}
				
		int tos_count_tMap_1 = 0;
		




// ###############################
// # Lookup's keys initialization
// ###############################        

// ###############################
// # Vars initialization
class  Var__tMap_1__Struct  {
}
Var__tMap_1__Struct Var__tMap_1 = new Var__tMap_1__Struct();
// ###############################

// ###############################
// # Outputs initialization
OutStruct Out_tmp = new OutStruct();
FaitStruct Fait_tmp = new FaitStruct();
// ###############################

        
        



        









 



/**
 * [tMap_1 begin ] stop
 */



	
	/**
	 * [tFileInputDelimited_1 begin ] start
	 */

	

	
		
		ok_Hash.put("tFileInputDelimited_1", false);
		start_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());
		
	
	currentComponent="tFileInputDelimited_1";

	
		int tos_count_tFileInputDelimited_1 = 0;
		
	
	
	
 
	
	
	final routines.system.RowState rowstate_tFileInputDelimited_1 = new routines.system.RowState();
	
	
				int nb_line_tFileInputDelimited_1 = 0;
				org.talend.fileprocess.FileInputDelimited fid_tFileInputDelimited_1 = null;
				int limit_tFileInputDelimited_1 = -1;
				try{
					
						Object filename_tFileInputDelimited_1 = "C:/Users/Administrateur.WIN-T87HKARVT4F/Documents/Sources_Hospitalisations/Hospitalisations.csv";
						if(filename_tFileInputDelimited_1 instanceof java.io.InputStream){
							
			int footer_value_tFileInputDelimited_1 = 0, random_value_tFileInputDelimited_1 = -1;
			if(footer_value_tFileInputDelimited_1 >0 || random_value_tFileInputDelimited_1 > 0){
				throw new java.lang.Exception("When the input source is a stream,footer and random shouldn't be bigger than 0.");				
			}
		
						}
						try {
							fid_tFileInputDelimited_1 = new org.talend.fileprocess.FileInputDelimited("C:/Users/Administrateur.WIN-T87HKARVT4F/Documents/Sources_Hospitalisations/Hospitalisations.csv", "US-ASCII",";","\n",false,1,0,
									limit_tFileInputDelimited_1
								,-1, false);
						} catch(java.lang.Exception e) {
							
								
								System.err.println(e.getMessage());
							
						}
					
				    
					while (fid_tFileInputDelimited_1!=null && fid_tFileInputDelimited_1.nextRecord()) {
						rowstate_tFileInputDelimited_1.reset();
						
			    						row1 = null;			
												
									boolean whetherReject_tFileInputDelimited_1 = false;
									row1 = new row1Struct();
									try {
										
				int columnIndexWithD_tFileInputDelimited_1 = 0;
				
					String temp = ""; 
				
					columnIndexWithD_tFileInputDelimited_1 = 0;
					
							row1.Num_Hospitalisation = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						
				
					columnIndexWithD_tFileInputDelimited_1 = 1;
					
						temp = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						if(temp.length() > 0) {
							
								try {
								
    								row1.Id_patient = ParserUtils.parseTo_Integer(temp);
    							
    							} catch(java.lang.Exception ex_tFileInputDelimited_1) {
									rowstate_tFileInputDelimited_1.setException(new RuntimeException(String.format("Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
										"Id_patient", "row1", temp, ex_tFileInputDelimited_1), ex_tFileInputDelimited_1));
								}
    							
						} else {						
							
								
									row1.Id_patient = null;
								
							
						}
					
				
					columnIndexWithD_tFileInputDelimited_1 = 2;
					
							row1.identifiant_organisation = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						
				
					columnIndexWithD_tFileInputDelimited_1 = 3;
					
							row1.Code_diagnostic = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						
				
					columnIndexWithD_tFileInputDelimited_1 = 4;
					
							row1.Suite_diagnostic_consultation = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						
				
					columnIndexWithD_tFileInputDelimited_1 = 5;
					
						temp = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						if(temp.length() > 0) {
							
								try {
								
    									row1.Date_Entree = ParserUtils.parseTo_Date(temp, "dd/MM/yyyy");
    								
    							} catch(java.lang.Exception ex_tFileInputDelimited_1) {
									rowstate_tFileInputDelimited_1.setException(new RuntimeException(String.format("Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
										"Date_Entree", "row1", temp, ex_tFileInputDelimited_1), ex_tFileInputDelimited_1));
								}
    							
						} else {						
							
								
									row1.Date_Entree = null;
								
							
						}
					
				
					columnIndexWithD_tFileInputDelimited_1 = 6;
					
						temp = fid_tFileInputDelimited_1.get(columnIndexWithD_tFileInputDelimited_1);
						if(temp.length() > 0) {
							
								try {
								
    								row1.Jour_Hospitalisation = ParserUtils.parseTo_Integer(temp);
    							
    							} catch(java.lang.Exception ex_tFileInputDelimited_1) {
									rowstate_tFileInputDelimited_1.setException(new RuntimeException(String.format("Couldn't parse value for column '%s' in '%s', value is '%s'. Details: %s",
										"Jour_Hospitalisation", "row1", temp, ex_tFileInputDelimited_1), ex_tFileInputDelimited_1));
								}
    							
						} else {						
							
								
									row1.Jour_Hospitalisation = null;
								
							
						}
					
				
				
										
										if(rowstate_tFileInputDelimited_1.getException()!=null) {
											throw rowstate_tFileInputDelimited_1.getException();
										}
										
										
							
			    					} catch (java.lang.Exception e) {
			        					whetherReject_tFileInputDelimited_1 = true;
			        					
			                					System.err.println(e.getMessage());
			                					row1 = null;
			                				
			    					}
								

 



/**
 * [tFileInputDelimited_1 begin ] stop
 */
	
	/**
	 * [tFileInputDelimited_1 main ] start
	 */

	

	
	
	currentComponent="tFileInputDelimited_1";

	

 


	tos_count_tFileInputDelimited_1++;

/**
 * [tFileInputDelimited_1 main ] stop
 */
	
	/**
	 * [tFileInputDelimited_1 process_data_begin ] start
	 */

	

	
	
	currentComponent="tFileInputDelimited_1";

	

 



/**
 * [tFileInputDelimited_1 process_data_begin ] stop
 */
// Start of branch "row1"
if(row1 != null) { 



	
	/**
	 * [tMap_1 main ] start
	 */

	

	
	
	currentComponent="tMap_1";

	
					if(execStat){
						runStat.updateStatOnConnection(iterateId,1,1,"row1");
					}
					

		
		
		boolean hasCasePrimitiveKeyWithNull_tMap_1 = false;
		
        // ###############################
        // # Input tables (lookups)
		  boolean rejectedInnerJoin_tMap_1 = false;
		  boolean mainRowRejected_tMap_1 = false;
            				    								  
		// ###############################
        { // start of Var scope
        
	        // ###############################
        	// # Vars tables
        
Var__tMap_1__Struct Var = Var__tMap_1;// ###############################
        // ###############################
        // # Output tables

Out = null;
Fait = null;


// # Output table : 'Out'
Out_tmp.Num_Hospitalisation = row1.Num_Hospitalisation;
Out_tmp.Date_Entree = row1.Date_Entree;
Out_tmp.Jour_Hospitalisation = row1.Jour_Hospitalisation;
Out = Out_tmp;

// # Output table : 'Fait'
Fait_tmp.Num_Hospitalisation = row1.Num_Hospitalisation ;
Fait_tmp.Id_patient = row1.Id_patient ;
Fait_tmp.Code_diagnostic = row1.Code_diagnostic ;
Fait = Fait_tmp;
// ###############################

} // end of Var scope

rejectedInnerJoin_tMap_1 = false;










 


	tos_count_tMap_1++;

/**
 * [tMap_1 main ] stop
 */
	
	/**
	 * [tMap_1 process_data_begin ] start
	 */

	

	
	
	currentComponent="tMap_1";

	

 



/**
 * [tMap_1 process_data_begin ] stop
 */
// Start of branch "Out"
if(Out != null) { 



	
	/**
	 * [tHDFSOutput_1 main ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_1";

	
					if(execStat){
						runStat.updateStatOnConnection(iterateId,1,1,"Out");
					}
					

	
					StringBuilder sb_tHDFSOutput_1 = new StringBuilder();
					
					
								if(Out.Num_Hospitalisation != null) {
							
									sb_tHDFSOutput_1.append(
										
											Out.Num_Hospitalisation
										
									);
							
								}
												
								sb_tHDFSOutput_1.append(";");
							
								if(Out.Date_Entree != null) {
							
									sb_tHDFSOutput_1.append(
										
											FormatterUtils.format_Date(Out.Date_Entree, "yyyy-MM-dd")
										
									);
							
								}
												
								sb_tHDFSOutput_1.append(";");
							
								if(Out.Jour_Hospitalisation != null) {
							
									sb_tHDFSOutput_1.append(
										
											Out.Jour_Hospitalisation
										
									);
							
								}
							
					sb_tHDFSOutput_1.append("\n");
					
						outtHDFSOutput_1.write(sb_tHDFSOutput_1.toString());
					
				nb_line_tHDFSOutput_1++;
				

	
 


	tos_count_tHDFSOutput_1++;

/**
 * [tHDFSOutput_1 main ] stop
 */
	
	/**
	 * [tHDFSOutput_1 process_data_begin ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_1";

	

 



/**
 * [tHDFSOutput_1 process_data_begin ] stop
 */
	
	/**
	 * [tHDFSOutput_1 process_data_end ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_1";

	

 



/**
 * [tHDFSOutput_1 process_data_end ] stop
 */

} // End of branch "Out"




// Start of branch "Fait"
if(Fait != null) { 



	
	/**
	 * [tHDFSOutput_2 main ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_2";

	
					if(execStat){
						runStat.updateStatOnConnection(iterateId,1,1,"Fait");
					}
					

	
					StringBuilder sb_tHDFSOutput_2 = new StringBuilder();
					
					
								if(Fait.Num_Hospitalisation != null) {
							
									sb_tHDFSOutput_2.append(
										
											Fait.Num_Hospitalisation
										
									);
							
								}
												
								sb_tHDFSOutput_2.append(";");
							
								if(Fait.Id_patient != null) {
							
									sb_tHDFSOutput_2.append(
										
											Fait.Id_patient
										
									);
							
								}
												
								sb_tHDFSOutput_2.append(";");
							
								if(Fait.Code_diagnostic != null) {
							
									sb_tHDFSOutput_2.append(
										
											Fait.Code_diagnostic
										
									);
							
								}
							
					sb_tHDFSOutput_2.append("\n");
					
						outtHDFSOutput_2.write(sb_tHDFSOutput_2.toString());
					
				nb_line_tHDFSOutput_2++;
				

	
 


	tos_count_tHDFSOutput_2++;

/**
 * [tHDFSOutput_2 main ] stop
 */
	
	/**
	 * [tHDFSOutput_2 process_data_begin ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_2";

	

 



/**
 * [tHDFSOutput_2 process_data_begin ] stop
 */
	
	/**
	 * [tHDFSOutput_2 process_data_end ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_2";

	

 



/**
 * [tHDFSOutput_2 process_data_end ] stop
 */

} // End of branch "Fait"




	
	/**
	 * [tMap_1 process_data_end ] start
	 */

	

	
	
	currentComponent="tMap_1";

	

 



/**
 * [tMap_1 process_data_end ] stop
 */

} // End of branch "row1"




	
	/**
	 * [tFileInputDelimited_1 process_data_end ] start
	 */

	

	
	
	currentComponent="tFileInputDelimited_1";

	

 



/**
 * [tFileInputDelimited_1 process_data_end ] stop
 */
	
	/**
	 * [tFileInputDelimited_1 end ] start
	 */

	

	
	
	currentComponent="tFileInputDelimited_1";

	



            }
            }finally{
                if(!((Object)("C:/Users/Administrateur.WIN-T87HKARVT4F/Documents/Sources_Hospitalisations/Hospitalisations.csv") instanceof java.io.InputStream)){
                	if(fid_tFileInputDelimited_1!=null){
                		fid_tFileInputDelimited_1.close();
                	}
                }
                if(fid_tFileInputDelimited_1!=null){
                	globalMap.put("tFileInputDelimited_1_NB_LINE", fid_tFileInputDelimited_1.getRowNumber());
					
                }
			}
			  

 

ok_Hash.put("tFileInputDelimited_1", true);
end_Hash.put("tFileInputDelimited_1", System.currentTimeMillis());




/**
 * [tFileInputDelimited_1 end ] stop
 */

	
	/**
	 * [tMap_1 end ] start
	 */

	

	
	
	currentComponent="tMap_1";

	


// ###############################
// # Lookup hashes releasing
// ###############################      





				if(execStat){
			  		runStat.updateStat(resourceMap,iterateId,2,0,"row1");
			  	}
			  	
 

ok_Hash.put("tMap_1", true);
end_Hash.put("tMap_1", System.currentTimeMillis());




/**
 * [tMap_1 end ] stop
 */

	
	/**
	 * [tHDFSOutput_1 end ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_1";

	


		if(outtHDFSOutput_1!=null){
			outtHDFSOutput_1.close();
		}

	
				if(execStat){
			  		runStat.updateStat(resourceMap,iterateId,2,0,"Out");
			  	}
			  	
 

ok_Hash.put("tHDFSOutput_1", true);
end_Hash.put("tHDFSOutput_1", System.currentTimeMillis());




/**
 * [tHDFSOutput_1 end ] stop
 */




	
	/**
	 * [tHDFSOutput_2 end ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_2";

	


		if(outtHDFSOutput_2!=null){
			outtHDFSOutput_2.close();
		}

	
				if(execStat){
			  		runStat.updateStat(resourceMap,iterateId,2,0,"Fait");
			  	}
			  	
 

ok_Hash.put("tHDFSOutput_2", true);
end_Hash.put("tHDFSOutput_2", System.currentTimeMillis());




/**
 * [tHDFSOutput_2 end ] stop
 */






				}//end the resume

				



	
			}catch(java.lang.Exception e){	
				
				TalendException te = new TalendException(e, currentComponent, globalMap);
				
				throw te;
			}catch(java.lang.Error error){	
				
					runStat.stopThreadStat();
				
				throw error;
			}finally{
				
				try{
					
	
	/**
	 * [tFileInputDelimited_1 finally ] start
	 */

	

	
	
	currentComponent="tFileInputDelimited_1";

	

 



/**
 * [tFileInputDelimited_1 finally ] stop
 */

	
	/**
	 * [tMap_1 finally ] start
	 */

	

	
	
	currentComponent="tMap_1";

	

 



/**
 * [tMap_1 finally ] stop
 */

	
	/**
	 * [tHDFSOutput_1 finally ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_1";

	

 



/**
 * [tHDFSOutput_1 finally ] stop
 */




	
	/**
	 * [tHDFSOutput_2 finally ] start
	 */

	

	
	
	currentComponent="tHDFSOutput_2";

	

 



/**
 * [tHDFSOutput_2 finally ] stop
 */






				}catch(java.lang.Exception e){	
					//ignore
				}catch(java.lang.Error error){
					//ignore
				}
				resourceMap = null;
			}
		

		globalMap.put("tFileInputDelimited_1_SUBPROCESS_STATE", 1);
	}
	
    public String resuming_logs_dir_path = null;
    public String resuming_checkpoint_path = null;
    public String parent_part_launcher = null;
    private String resumeEntryMethodName = null;
    private boolean globalResumeTicket = false;

    public boolean watch = false;
    // portStats is null, it means don't execute the statistics
    public Integer portStats = null;
    public int portTraces = 4334;
    public String clientHost;
    public String defaultClientHost = "localhost";
    public String contextStr = "Default";
    public boolean isDefaultContext = true;
    public String pid = "0";
    public String rootPid = null;
    public String fatherPid = null;
    public String fatherNode = null;
    public long startTime = 0;
    public boolean isChildJob = false;
    public String log4jLevel = "";
    
    private boolean enableLogStash;

    private boolean execStat = true;

    private ThreadLocal<java.util.Map<String, String>> threadLocal = new ThreadLocal<java.util.Map<String, String>>() {
        protected java.util.Map<String, String> initialValue() {
            java.util.Map<String,String> threadRunResultMap = new java.util.HashMap<String, String>();
            threadRunResultMap.put("errorCode", null);
            threadRunResultMap.put("status", "");
            return threadRunResultMap;
        };
    };


    private PropertiesWithType context_param = new PropertiesWithType();
    public java.util.Map<String, Object> parentContextMap = new java.util.HashMap<String, Object>();

    public String status= "";
    

    public static void main(String[] args){
        final Extract_Visite Extract_VisiteClass = new Extract_Visite();

        int exitCode = Extract_VisiteClass.runJobInTOS(args);

        System.exit(exitCode);
    }


    public String[][] runJob(String[] args) {

        int exitCode = runJobInTOS(args);
        String[][] bufferValue = new String[][] { { Integer.toString(exitCode) } };

        return bufferValue;
    }

    public boolean hastBufferOutputComponent() {
		boolean hastBufferOutput = false;
    	
        return hastBufferOutput;
    }

    public int runJobInTOS(String[] args) {
	   	// reset status
	   	status = "";
	   	
        String lastStr = "";
        for (String arg : args) {
            if (arg.equalsIgnoreCase("--context_param")) {
                lastStr = arg;
            } else if (lastStr.equals("")) {
                evalParam(arg);
            } else {
                evalParam(lastStr + " " + arg);
                lastStr = "";
            }
        }
        enableLogStash = "true".equalsIgnoreCase(System.getProperty("monitoring"));

    	
    	

        if(clientHost == null) {
            clientHost = defaultClientHost;
        }

        if(pid == null || "0".equals(pid)) {
            pid = TalendString.getAsciiRandomString(6);
        }

        if (rootPid==null) {
            rootPid = pid;
        }
        if (fatherPid==null) {
            fatherPid = pid;
        }else{
            isChildJob = true;
        }

        if (portStats != null) {
            // portStats = -1; //for testing
            if (portStats < 0 || portStats > 65535) {
                // issue:10869, the portStats is invalid, so this client socket can't open
                System.err.println("The statistics socket port " + portStats + " is invalid.");
                execStat = false;
            }
        } else {
            execStat = false;
        }

        try {
            //call job/subjob with an existing context, like: --context=production. if without this parameter, there will use the default context instead.
            java.io.InputStream inContext = Extract_Visite.class.getClassLoader().getResourceAsStream("bigdata_project/extract_visite_0_1/contexts/" + contextStr + ".properties");
            if (inContext == null) {
                inContext = Extract_Visite.class.getClassLoader().getResourceAsStream("config/contexts/" + contextStr + ".properties");
            }
            if (inContext != null) {
                //defaultProps is in order to keep the original context value
                if(context != null && context.isEmpty()) {
	                defaultProps.load(inContext);
	                context = new ContextProperties(defaultProps);
                }
                
                inContext.close();
            } else if (!isDefaultContext) {
                //print info and job continue to run, for case: context_param is not empty.
                System.err.println("Could not find the context " + contextStr);
            }

            if(!context_param.isEmpty()) {
                context.putAll(context_param);
				//set types for params from parentJobs
				for (Object key: context_param.keySet()){
					String context_key = key.toString();
					String context_type = context_param.getContextType(context_key);
					context.setContextType(context_key, context_type);

				}
            }
            class ContextProcessing {
                private void processContext_0() {
                        context.setContextType("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable", "id_String");
                            context.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable=(String) context.getProperty("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable");
                        context.setContextType("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy", "id_String");
                            context.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy=(String) context.getProperty("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy");
                        context.setContextType("HadoopHDFS_HdfsFileSeparator", "id_String");
                            context.HadoopHDFS_HdfsFileSeparator=(String) context.getProperty("HadoopHDFS_HdfsFileSeparator");
                        context.setContextType("HadoopHDFS_HdfsRowSeparator", "id_String");
                            context.HadoopHDFS_HdfsRowSeparator=(String) context.getProperty("HadoopHDFS_HdfsRowSeparator");
                        context.setContextType("HadoopHDFS_HdfsUser", "id_String");
                            context.HadoopHDFS_HdfsUser=(String) context.getProperty("HadoopHDFS_HdfsUser");
                        context.setContextType("HadoopHDFS_Hospi", "id_String");
                            context.HadoopHDFS_Hospi=(String) context.getProperty("HadoopHDFS_Hospi");
                        context.setContextType("HadoopHDFS_VisiteFile", "id_String");
                            context.HadoopHDFS_VisiteFile=(String) context.getProperty("HadoopHDFS_VisiteFile");
                        context.setContextType("ProjectHadoopCluster_NameNodeUri", "id_String");
                            context.ProjectHadoopCluster_NameNodeUri=(String) context.getProperty("ProjectHadoopCluster_NameNodeUri");
                        context.setContextType("ProjectHadoopCluster_User", "id_String");
                            context.ProjectHadoopCluster_User=(String) context.getProperty("ProjectHadoopCluster_User");
                } 
                public void processAllContext() {
                        processContext_0();
                }
            }

            new ContextProcessing().processAllContext();
        } catch (java.io.IOException ie) {
            System.err.println("Could not load context "+contextStr);
            ie.printStackTrace();
        }

        // get context value from parent directly
        if (parentContextMap != null && !parentContextMap.isEmpty()) {if (parentContextMap.containsKey("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable")) {
                context.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable = (String) parentContextMap.get("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_enable");
            }if (parentContextMap.containsKey("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy")) {
                context.HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy = (String) parentContextMap.get("HadoopHDFS_dfs_client_block_write_replace_datanode_on_failure_policy");
            }if (parentContextMap.containsKey("HadoopHDFS_HdfsFileSeparator")) {
                context.HadoopHDFS_HdfsFileSeparator = (String) parentContextMap.get("HadoopHDFS_HdfsFileSeparator");
            }if (parentContextMap.containsKey("HadoopHDFS_HdfsRowSeparator")) {
                context.HadoopHDFS_HdfsRowSeparator = (String) parentContextMap.get("HadoopHDFS_HdfsRowSeparator");
            }if (parentContextMap.containsKey("HadoopHDFS_HdfsUser")) {
                context.HadoopHDFS_HdfsUser = (String) parentContextMap.get("HadoopHDFS_HdfsUser");
            }if (parentContextMap.containsKey("HadoopHDFS_Hospi")) {
                context.HadoopHDFS_Hospi = (String) parentContextMap.get("HadoopHDFS_Hospi");
            }if (parentContextMap.containsKey("HadoopHDFS_VisiteFile")) {
                context.HadoopHDFS_VisiteFile = (String) parentContextMap.get("HadoopHDFS_VisiteFile");
            }if (parentContextMap.containsKey("ProjectHadoopCluster_NameNodeUri")) {
                context.ProjectHadoopCluster_NameNodeUri = (String) parentContextMap.get("ProjectHadoopCluster_NameNodeUri");
            }if (parentContextMap.containsKey("ProjectHadoopCluster_User")) {
                context.ProjectHadoopCluster_User = (String) parentContextMap.get("ProjectHadoopCluster_User");
            }
        }

        //Resume: init the resumeUtil
        resumeEntryMethodName = ResumeUtil.getResumeEntryMethodName(resuming_checkpoint_path);
        resumeUtil = new ResumeUtil(resuming_logs_dir_path, isChildJob, rootPid);
        resumeUtil.initCommonInfo(pid, rootPid, fatherPid, projectName, jobName, contextStr, jobVersion);

		List<String> parametersToEncrypt = new java.util.ArrayList<String>();
        //Resume: jobStart
        resumeUtil.addLog("JOB_STARTED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "", "","","","",resumeUtil.convertToJsonText(context,parametersToEncrypt));

if(execStat) {
    try {
        runStat.openSocket(!isChildJob);
        runStat.setAllPID(rootPid, fatherPid, pid, jobName);
        runStat.startThreadStat(clientHost, portStats);
        runStat.updateStatOnJob(RunStat.JOBSTART, fatherNode);
    } catch (java.io.IOException ioException) {
        ioException.printStackTrace();
    }
}



	
	    java.util.concurrent.ConcurrentHashMap<Object, Object> concurrentHashMap = new java.util.concurrent.ConcurrentHashMap<Object, Object>();
	    globalMap.put("concurrentHashMap", concurrentHashMap);
	

    long startUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
    long endUsedMemory = 0;
    long end = 0;

    startTime = System.currentTimeMillis();




this.globalResumeTicket = true;//to run tPreJob




this.globalResumeTicket = false;//to run others jobs

try {
errorCode = null;tHDFSConnection_1Process(globalMap);
if(!"failure".equals(status)) { status = "end"; }
}catch (TalendException e_tHDFSConnection_1) {
globalMap.put("tHDFSConnection_1_SUBPROCESS_STATE", -1);

e_tHDFSConnection_1.printStackTrace();

}

this.globalResumeTicket = true;//to run tPostJob




        end = System.currentTimeMillis();

        if (watch) {
            System.out.println((end-startTime)+" milliseconds");
        }

        endUsedMemory = Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory();
        if (false) {
            System.out.println((endUsedMemory - startUsedMemory) + " bytes memory increase when running : Extract_Visite");
        }



if (execStat) {
    runStat.updateStatOnJob(RunStat.JOBEND, fatherNode);
    runStat.stopThreadStat();
}
    int returnCode = 0;
    if(errorCode == null) {
         returnCode = status != null && status.equals("failure") ? 1 : 0;
    } else {
         returnCode = errorCode.intValue();
    }
    resumeUtil.addLog("JOB_ENDED", "JOB:" + jobName, parent_part_launcher, Thread.currentThread().getId() + "", "","" + returnCode,"","","");

    return returnCode;

  }

    // only for OSGi env
    public void destroy() {


    }














    private java.util.Map<String, Object> getSharedConnections4REST() {
        java.util.Map<String, Object> connections = new java.util.HashMap<String, Object>();







        return connections;
    }

    private void evalParam(String arg) {
        if (arg.startsWith("--resuming_logs_dir_path")) {
            resuming_logs_dir_path = arg.substring(25);
        } else if (arg.startsWith("--resuming_checkpoint_path")) {
            resuming_checkpoint_path = arg.substring(27);
        } else if (arg.startsWith("--parent_part_launcher")) {
            parent_part_launcher = arg.substring(23);
        } else if (arg.startsWith("--watch")) {
            watch = true;
        } else if (arg.startsWith("--stat_port=")) {
            String portStatsStr = arg.substring(12);
            if (portStatsStr != null && !portStatsStr.equals("null")) {
                portStats = Integer.parseInt(portStatsStr);
            }
        } else if (arg.startsWith("--trace_port=")) {
            portTraces = Integer.parseInt(arg.substring(13));
        } else if (arg.startsWith("--client_host=")) {
            clientHost = arg.substring(14);
        } else if (arg.startsWith("--context=")) {
            contextStr = arg.substring(10);
            isDefaultContext = false;
        } else if (arg.startsWith("--father_pid=")) {
            fatherPid = arg.substring(13);
        } else if (arg.startsWith("--root_pid=")) {
            rootPid = arg.substring(11);
        } else if (arg.startsWith("--father_node=")) {
            fatherNode = arg.substring(14);
        } else if (arg.startsWith("--pid=")) {
            pid = arg.substring(6);
        } else if (arg.startsWith("--context_type")) {
            String keyValue = arg.substring(15);
			int index = -1;
            if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
                if (fatherPid==null) {
                    context_param.setContextType(keyValue.substring(0, index), replaceEscapeChars(keyValue.substring(index + 1)));
                } else { // the subjob won't escape the especial chars
                    context_param.setContextType(keyValue.substring(0, index), keyValue.substring(index + 1) );
                }

            }

		} else if (arg.startsWith("--context_param")) {
            String keyValue = arg.substring(16);
            int index = -1;
            if (keyValue != null && (index = keyValue.indexOf('=')) > -1) {
                if (fatherPid==null) {
                    context_param.put(keyValue.substring(0, index), replaceEscapeChars(keyValue.substring(index + 1)));
                } else { // the subjob won't escape the especial chars
                    context_param.put(keyValue.substring(0, index), keyValue.substring(index + 1) );
                }
            }
        } else if (arg.startsWith("--log4jLevel=")) {
            log4jLevel = arg.substring(13);
		} else if (arg.startsWith("--monitoring") && arg.contains("=")) {//for trunjob call
		    final int equal = arg.indexOf('=');
			final String key = arg.substring("--".length(), equal);
			System.setProperty(key, arg.substring(equal + 1));
		}
    }
    
    private static final String NULL_VALUE_EXPRESSION_IN_COMMAND_STRING_FOR_CHILD_JOB_ONLY = "<TALEND_NULL>";

    private final String[][] escapeChars = {
        {"\\\\","\\"},{"\\n","\n"},{"\\'","\'"},{"\\r","\r"},
        {"\\f","\f"},{"\\b","\b"},{"\\t","\t"}
        };
    private String replaceEscapeChars (String keyValue) {

		if (keyValue == null || ("").equals(keyValue.trim())) {
			return keyValue;
		}

		StringBuilder result = new StringBuilder();
		int currIndex = 0;
		while (currIndex < keyValue.length()) {
			int index = -1;
			// judege if the left string includes escape chars
			for (String[] strArray : escapeChars) {
				index = keyValue.indexOf(strArray[0],currIndex);
				if (index>=0) {

					result.append(keyValue.substring(currIndex, index + strArray[0].length()).replace(strArray[0], strArray[1]));
					currIndex = index + strArray[0].length();
					break;
				}
			}
			// if the left string doesn't include escape chars, append the left into the result
			if (index < 0) {
				result.append(keyValue.substring(currIndex));
				currIndex = currIndex + keyValue.length();
			}
		}

		return result.toString();
    }

    public Integer getErrorCode() {
        return errorCode;
    }


    public String getStatus() {
        return status;
    }

    ResumeUtil resumeUtil = null;
}
/************************************************************************************************
 *     74191 characters generated by Talend Open Studio for Big Data 
 *     on the 19 mai 2022 01:43:37 CEST
 ************************************************************************************************/